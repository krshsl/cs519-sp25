--- ./linux-5.15.0/kernel/sched/core.c.orig	2025-05-07 16:58:08.946133446 -0600
+++ ./linux-5.15.0/kernel/sched/core.c	2025-05-08 20:04:57.002343869 -0600
@@ -6,6 +6,10 @@
  *
  *  Copyright (C) 1991-2002  Linus Torvalds
  */
+#include "linux/rbtree_types.h"
+#include "linux/sched.h"
+#include "linux/spinlock.h"
+#include "linux/stddef.h"
 #define CREATE_TRACE_POINTS
 #include <trace/events/sched.h>
 #undef CREATE_TRACE_POINTS
@@ -27,6 +31,10 @@
 #include "pelt.h"
 #include "smp.h"
 
+#include <linux/my_inactive.h>
+
+DEFINE_PER_CPU(struct inactive_cpu, ia_cpu_queue);
+EXPORT_PER_CPU_SYMBOL(ia_cpu_queue);
 /*
  * Export tracepoints that act as a bare tracehook (ie: have no trace event
  * associated with them) to allow external modules to probe them.
@@ -9546,6 +9554,13 @@
 #endif
 	}
 
+	for_each_possible_cpu(i) {
+        struct inactive_cpu *ia_cpu = &per_cpu(ia_cpu_queue, i);
+        ia_cpu->lock = __RAW_SPIN_LOCK_UNLOCKED(node->lock);
+        ia_cpu->counter = 0;
+        INIT_LIST_HEAD(&ia_cpu->proc_list);
+	}
+
 	set_load_weight(&init_task, false);
 
 	/*
@@ -10981,3 +10996,55 @@
 {
         trace_sched_update_nr_running_tp(rq, count);
 }
+
+SYSCALL_DEFINE3(set_inactive_pid, int, upid, int, task_core, unsigned long long, inactive_time) {
+    struct task_struct *p;
+    struct inactive_cpu *cpu = NULL;
+    struct inactive_tasks *task = NULL;
+    struct inactive_tasks *node = NULL;
+    struct list_head *pos = NULL;
+    struct list_head *tmp = NULL;
+    unsigned long cpu_flags;
+    struct pid* pid;
+
+    LOG_FUNCS(KERN_INFO, "Begins... %d::%d::%d", current->pid, upid, smp_processor_id());
+    pid = find_vpid(upid);
+    p = pid_task(pid, PIDTYPE_PID);
+    if (p == NULL) {
+        LOG_FUNCS(KERN_INFO, "Proc::%d exited. Ending...", upid);
+        return 0; // process has already exited, no need to add...
+    }
+
+    inactive_time = max_t(u64, inactive_time, 20000LL); // inactive_time should atleast be 2 times the sched val...
+    LOG_FUNCS(KERN_INFO, "%d:%d:%d:%llu", current->pid, upid, task_core, inactive_time);
+    cpu = &per_cpu(ia_cpu_queue, task_core);
+    if (cpu == NULL) { // can never be null cause it is always supposed to exist??
+        LOG_FUNCS(KERN_INFO, "Something seriously broke in %d::%d, but what did???", current->pid, task_core);
+        return -EFAULT;
+    }
+
+    raw_spin_lock_irqsave(&cpu->lock, cpu_flags);
+    list_for_each_safe(pos, tmp, &cpu->proc_list) {
+        node = list_entry(pos, struct inactive_tasks, head);
+    	if (node->pid != upid) continue;
+        task = node;
+    }
+
+    if (task) {
+        LOG_FUNCS(KERN_INFO, "Existing key updated... %d::%d", upid, task_core);
+        task->inactive_time = inactive_time;
+    } else {
+        LOG_FUNCS(KERN_INFO, "New Key added... %d::%d", upid, task_core);
+        task = kmalloc(sizeof(struct inactive_tasks), GFP_KERNEL);
+        task->pid = upid;
+        task->inactive_time = inactive_time;
+        INIT_LIST_HEAD(&task->head);
+        list_add_tail(&task->head, &cpu->proc_list);
+        cpu->counter++;
+    }
+    p->inactive_tracker = current->pid; // parent pid added to inactive tracker
+    p->inactive_cpu = task_core;
+    raw_spin_unlock_irqrestore(&cpu->lock, cpu_flags);
+    LOG_FUNCS(KERN_INFO, "Ends... %d::%d::%d", current->pid, upid, smp_processor_id());
+    return 0;
+}
